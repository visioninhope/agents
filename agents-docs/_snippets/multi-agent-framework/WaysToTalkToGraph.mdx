You can talk to an Inkeep Agent (graph) in a few ways, including:

- **UI Chat Components**: Drop-in React components for chat UIs with built-in streaming and rich UI customization. See [React Chat Button](/talk-to-your-agents/react/chat-button).
- **As an MCP server**: Use your Inkeep Agent as if was an MCP Server. Allows you to connect it to any MCP client, like Claude, ChatGPT, Claude and other Agents. See [MCP server](/talk-to-your-agents/mcp-server).
- **Via API (Vercal format)**: An API that streams responses over a server-side events (SSE) data-stream format. Use from any language/runtime, including the Vercel AI SDK. See [API (Vercel format)](/talk-to-your-agents/api).
- **Via API (A2A format)**: An API that follows the Agent-to-Agent ('A2A') JSON-RPC protocol. Great for when combining Inkeep with different Agent frameworks that support the A2A format. See [A2A protocol](/talk-to-your-agents/a2a).

<Cards>
  <Card title="React UI" icon="LuMessageSquare" href="/talk-to-your-agents/react/chat-button">
    Drop-in chat components for React apps with streaming and rich UI.
  </Card>
  <Card title="API (Vercel format)" icon="LuNetwork" href="/talk-to-your-agents/api">
    POST /api/chat, SSE (text/event-stream), x-vercel-ai-data-stream: v2.
  </Card>
  <Card title="A2A protocol" icon="LuNetwork" href="/talk-to-your-agents/a2a">
    JSON-RPC messages at /agents/a2a with blocking and streaming modes.
  </Card>
  <Card title="MCP server" icon="LuServer" href="/talk-to-your-agents/mcp-server">
    HTTP JSON-RPC endpoint at /v1/mcp with session header management.
  </Card>
</Cards>


